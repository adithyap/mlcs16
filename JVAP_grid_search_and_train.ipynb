{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,make_scorer,f1_score,classification_report,average_precision_score\n",
    "from sklearn.preprocessing import Normalizer,MinMaxScaler,StandardScaler,normalize\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# PANDAS HELPERS\n",
    "#############################################\n",
    "\n",
    "def remove_column_from_data_frame(col_to_remove, data_frame):\n",
    "\n",
    "    if col_to_remove in list(data_frame.columns):\n",
    "        data_frame.drop(col_to_remove, axis=1, inplace=True)\n",
    "\n",
    "        \n",
    "def remove_columns_from_data_frame(cols_to_remove, data_frame):\n",
    "\n",
    "    column_dict = {x: None for x in list(data_frame.columns)}\n",
    "\n",
    "    cols_to_remove = [x for x in cols_to_remove if x in column_dict]\n",
    "\n",
    "    data_frame.drop(labels=cols_to_remove, axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "def remove_columns_like(column_pattern, data_frame):\n",
    "    \n",
    "    for column in list(data_frame.columns):\n",
    "        if column_pattern in column:\n",
    "            data_frame.drop(column, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "def fill_nas(value, data_frame):\n",
    "    \n",
    "    data_frame.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# DATA RETRIEVAL HELPERS\n",
    "#############################################\n",
    "\n",
    "def get_data(n_rows=None):\n",
    "\n",
    "    if n_rows is not None:\n",
    "        df = pd.get_dummies(pd.read_csv('final_feats_without_dummies.csv', low_memory=False, nrows=n_rows))\n",
    "        df_y = pd.get_dummies(pd.read_csv('final_outs.csv', low_memory=False, nrows=n_rows))\n",
    "    else:\n",
    "        df = pd.get_dummies(pd.read_csv('final_feats_without_dummies.csv', low_memory=False))\n",
    "        df_y = pd.get_dummies(pd.read_csv('final_outs.csv', low_memory=False))\n",
    "    \n",
    "    \n",
    "    # Drop labels and a redundant column\n",
    "    remove_columns_from_data_frame(['Unnamed: 0', 'Unnamed: 0.1' 'dissent', 'dissentdummy'], df)\n",
    "    \n",
    "    # Extras -- for analysis\n",
    "    # CASE 1: REMOVE TOP 2\n",
    "    # CASE 2: REMOVE ALL 'DISS'\n",
    "    \n",
    "#     remove_columns_from_data_frame(['type', 'turnonthresh'], df)\n",
    "#     remove_columns_from_data_frame(['type1', 'last3'], df)\n",
    "#     remove_columns_like('diss', df)\n",
    "    \n",
    "    return df, df_y\n",
    "\n",
    "\n",
    "def get_x_y(n_rows=None):\n",
    "    \n",
    "    df, df_y = get_data(n_rows)\n",
    "\n",
    "    fill_nas(0, df)\n",
    "    \n",
    "    return df.values, df_y.ix[:,1].values\n",
    "\n",
    "\n",
    "def get_columns():\n",
    "    \n",
    "    df = pd.get_dummies(pd.read_csv('final_feats_without_dummies.csv', low_memory=False, nrows=2))\n",
    "    return list(df.columns)\n",
    "\n",
    "\n",
    "def print_report(y, y_pred):\n",
    "\n",
    "    print classification_report(y, y_pred)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# MODEL HELPERS\n",
    "#############################################\n",
    "\n",
    "def grid_search(X, y, clf, param_grid):\n",
    "    \n",
    "#     param_dict={'average': 'weighted'}\n",
    "    scorer = make_scorer(average_precision_score)\n",
    "\n",
    "\n",
    "    gridclf = GridSearchCV(clf, paramgrid, scoring=scorer, cv=3, verbose=1)\n",
    "\n",
    "    gridclf.fit(X, y)\n",
    "\n",
    "    print gridclf.best_params_\n",
    "    print gridclf.best_estimator_\n",
    "\n",
    "    print_report(y_test, gridclf.predict(X_test))\n",
    "    \n",
    "\n",
    "def get_top_n(n, arr, col_names, prev_list=[]):\n",
    "    \n",
    "    if n <= 0:\n",
    "        return []\n",
    "    \n",
    "    most_imp = -1\n",
    "    most_imp_index = -1\n",
    "\n",
    "    for i in range(len(arr)):\n",
    "\n",
    "        if i in prev_list:\n",
    "            continue\n",
    "\n",
    "        if arr[i] > most_imp:\n",
    "            most_imp = arr[i]\n",
    "            most_imp_index = i\n",
    "\n",
    "    prev_list.append(most_imp_index)\n",
    "\n",
    "    return [ (col_names[most_imp_index], most_imp) ] + get_top_n(n - 1, arr, col_names, prev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Read data into X and y\n",
    "#############################################\n",
    "\n",
    "X, y = get_x_y(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Split into training and test set\n",
    "#############################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Standard scale\n",
    "#############################################\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "{'n_estimators': 50, 'max_depth': 5}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.98       238\n",
      "        1.0       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.91      0.95      0.93       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    3.7s finished\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# [OPTIONAL]\n",
    "# Random Forest Grid Search\n",
    "#############################################\n",
    "\n",
    "paramgrid = {'n_estimators': [10, 50, 100], 'max_depth': [1, 5, 10, 15]}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search(X_train, y_train, rf_clf, paramgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.73      0.49      0.58      2280\n",
      "          1       0.98      0.99      0.99     53553\n",
      "\n",
      "avg / total       0.97      0.97      0.97     55833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# Random Forest\n",
    "#############################################\n",
    "\n",
    "# Replace labels (in case SVM was run)\n",
    "# y_train[y_train == 0.] = -1.\n",
    "# y_test[y_test == 0.] = -1.\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42, \n",
    "                                n_estimators=100, \n",
    "                                max_depth=15, \n",
    "#                                 class_weight={1.0: 1, -1.0: 150})\n",
    "                                )\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "print_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('type1', 0.085836245627072427)\n",
      "('last3', 0.057453894299753429)\n",
      "('close2', 0.013785569650024256)\n",
      "('close3', 0.013742677538063049)\n",
      "('diss0promerdummy', 0.0065234843229324416)\n",
      "('unanimous', 0.0057345487383386635)\n",
      "('dissent', 0.0047420628379996922)\n",
      "('din', 0.0043813667302849586)\n",
      "('concprodummy', 0.0036449179471683664)\n",
      "('keytotal', 0.0035560335123791609)\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# [OPTIONAL]\n",
    "# Feature importance analysis\n",
    "#############################################\n",
    "\n",
    "top_n = get_top_n(10, rf_clf.feature_importances_, get_columns())\n",
    "\n",
    "for t in top_n:\n",
    "    print t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    4.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:   15.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n",
      "{'kernel': 'poly', 'max_iter': 1000, 'coef0': 1000.0, 'degree': 1, 'class_weight': {1.0: 1, -1.0: 150}}\n",
      "SVC(C=1.0, cache_size=200, class_weight={1.0: 1, -1.0: 150}, coef0=1000.0,\n",
      "  decision_function_shape=None, degree=1, gamma='auto', kernel='poly',\n",
      "  max_iter=1000, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00        11\n",
      "          1       0.98      1.00      0.99       489\n",
      "\n",
      "avg / total       0.96      0.98      0.97       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:   18.5s finished\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# [OPTIONAL]\n",
    "# SVM Grid Search\n",
    "#############################################\n",
    "\n",
    "paramgrid = {'kernel': ['rbf', 'poly', 'sigmoid', 'linear'], \n",
    "             'degree': [1, 3, 5, 7, 9], \n",
    "             'coef0': [1e-3, 1e-1, 1e1, 1e3], \n",
    "             'max_iter': [1000], \n",
    "             'class_weight': [{1.0: 1, -1.0: 150}]}\n",
    "\n",
    "svm_clf = SVC()\n",
    "\n",
    "grid_search(X_train, y_train, svm_clf, paramgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00        11\n",
      "          1       0.98      1.00      0.99       489\n",
      "\n",
      "avg / total       0.96      0.98      0.97       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SVM\n",
    "#############################################\n",
    "\n",
    "# Replace labels\n",
    "# y_train[y_train == 0.] = -1.\n",
    "# y_test[y_test == 0.] = -1.\n",
    "\n",
    "svm_clf = SVC(kernel='rbf', max_iter=1000, coef0=1e-3, degree=2, class_weight={1.0: 1, -1.0: 150})\n",
    "\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "print_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tdf = pd.get_dummies(pd.read_csv('final_outs.csv', low_memory=False))\n",
    "\n",
    "# pd.unique(tdf.ix[:,1].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
