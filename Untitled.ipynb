{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,make_scorer,f1_score,classification_report,average_precision_score\n",
    "from sklearn.preprocessing import Normalizer,MinMaxScaler,StandardScaler,normalize\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(n_rows=None):\n",
    "    \n",
    "    if n_rows is not None:\n",
    "        df = pd.read_csv('final_feats_without_dummies_3.csv', low_memory=False, nrows=n_rows)\n",
    "        df_y = pd.read_csv('final_outs_3.csv', low_memory=False, nrows=n_rows)\n",
    "    else:\n",
    "        df = pd.read_csv('final_feats_without_dummies_3.csv', low_memory=False)\n",
    "        df_y = pd.read_csv('final_outs_3.csv', low_memory=False)\n",
    "    \n",
    "    \n",
    "    # Drop labels and a redundant column\n",
    "    remove_columns_from_data_frame(['Unnamed: 0', 'Unnamed: 0.1' 'dissent', 'dissentdummy'], df)\n",
    "#     df,df_y=remove_bad_rows(df,df_y)\n",
    "#     df=drop_unneeded_cols(df)\n",
    "#     df=drop_dissent(df)\n",
    "#     df=dummify(df)\n",
    "    \n",
    "    # Extras -- for analysis\n",
    "    # CASE 1: REMOVE TOP 2\n",
    "    # CASE 2: REMOVE ALL 'DISS'\n",
    "    \n",
    "#     remove_columns_from_data_frame(['type', 'turnonthresh'], df)\n",
    "#     remove_columns_from_data_frame(['type1', 'last3'], df)\n",
    "#     remove_columns_like('diss', df)\n",
    "    if ('Unnamed: 0' or 'Unnamed: 0.1') in df_y.columns:\n",
    "        df_y.drop(labels=['Unnamed: 0','Unnamed: 0.1'],axis=1,inplace=True)\n",
    "    \n",
    "    return df, df_y\n",
    "\n",
    "\n",
    "def get_x_y(n_rows=None):\n",
    "    \n",
    "    df, df_y = get_data(n_rows)\n",
    "\n",
    "    #fill_nas(0, df)\n",
    "    for y in df_y.columns:\n",
    "        if len(pd.unique(df_y.ix[:,y]))==2:\n",
    "\t\ty=df_y.ix[:,y].values\n",
    "\t\tbreak\n",
    "    return df.values, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#############################################\n",
    "# PANDAS HELPERS\n",
    "#############################################\n",
    "\n",
    "\n",
    "def remove_column_from_data_frame(col_to_remove, data_frame):\n",
    "\n",
    "    if col_to_remove in list(data_frame.columns):\n",
    "        data_frame.drop(col_to_remove, axis=1, inplace=True)\n",
    "\n",
    "        \n",
    "def remove_columns_from_data_frame(cols_to_remove, data_frame):\n",
    "\n",
    "    column_dict = {x: None for x in list(data_frame.columns)}\n",
    "\n",
    "    cols_to_remove = [x for x in cols_to_remove if x in column_dict]\n",
    "\n",
    "    data_frame.drop(labels=cols_to_remove, axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "def remove_columns_like(column_pattern, data_frame):\n",
    "    \n",
    "    for column in list(data_frame.columns):\n",
    "        if column_pattern in column:\n",
    "            data_frame.drop(column, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "def fill_nas(value, data_frame):\n",
    "    \n",
    "    data_frame.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#############################################\n",
    "# DATA RETRIEVAL HELPERS\n",
    "#############################################\n",
    "\n",
    "\n",
    "def get_columns():\n",
    "    \n",
    "    df, df_y = get_data(1000) \n",
    "    return list(df.columns)\n",
    "\n",
    "\n",
    "def print_report(y, y_pred):\n",
    "\n",
    "    print classification_report(y, y_pred)\n",
    "    \n",
    "\n",
    "#############################################\n",
    "# MODEL HELPERS\n",
    "#############################################\n",
    "\n",
    "def grid_search(X, y, clf, param_grid, n_jobs=1):\n",
    "    \n",
    "#     param_dict={'average': 'weighted'}\n",
    "    scorer = make_scorer(average_precision_score)\n",
    "\n",
    "\n",
    "    gridclf = GridSearchCV(clf, paramgrid, scoring=scorer, cv=3, verbose=1, n_jobs=n_jobs)\n",
    "\n",
    "    gridclf.fit(X, y)\n",
    "\n",
    "    print gridclf.best_params_\n",
    "    print gridclf.best_estimator_\n",
    "\n",
    "    print_report(y_test, gridclf.predict(X_test))\n",
    "    \n",
    "    return gridclf\n",
    "\n",
    "\n",
    "def get_top_n_feats(n, feat_arr, cols):\n",
    "    args=np.argsort(feat_arr)\n",
    "    assert len(feat_arr)==len(cols)\n",
    "    col_scores=col_scores=np.array(zip(cols,feat_arr))\n",
    "    return col_scores[args[-n:]].tolist()[::-1]\n",
    "\n",
    "\n",
    "# def get_top_n(n, arr, col_names, prev_list=[]):\n",
    "    \n",
    "#     if n <= 0:\n",
    "#         return []\n",
    "    \n",
    "#     most_imp = -1\n",
    "#     most_imp_index = -1\n",
    "\n",
    "#     for i in range(len(arr)):\n",
    "\n",
    "#         if i in prev_list:\n",
    "#             continue\n",
    "\n",
    "#         if arr[i] > most_imp:\n",
    "#             most_imp = arr[i]\n",
    "#             most_imp_index = i\n",
    "\n",
    "#     prev_list.append(most_imp_index)\n",
    "\n",
    "#     return [ (col_names[most_imp_index], most_imp) ] + get_top_n(n - 1, arr, col_names, prev_list)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "def drop_unneeded_cols(df):\n",
    "    del_cols = ['fileid','cite','vol','beginpg','endopin','endpage','docnum','priorpub','_merge','year',\n",
    "            'circuit','pseatno','decision_date','aatty_first_name','aatty_last_name','afirm_name',\n",
    "            'ratty_first_name','ratty_last_name','rname_of_first_listed_amicus_gro','rfirm_namew','decisiondatenew2',\n",
    "           'j1name','j2name','j3name','quartertoelect','pname','seatno','success','lsuc','ls1','ls2','ls3','lp',\n",
    "            'lp2','lp3','sseatno','congress','congreso','afirst_listed_amicus_group','yearquarter','name','Name','State','j',\n",
    "            'codej4','j4vote1','j4vote2','j4maj1','j4maj2','codej5','j5vote1','j5vote2','j5maj1','j5maj2',\n",
    "            'codej6','j6vote1','j6vote2','j6maj1','j6maj2','codej7','j7vote1','j7vote2','j7maj1','j7maj2',\n",
    "            'codej8','j8vote1','j8vote2','j8maj1','j8maj2','codej9','j9vote1','j9vote2','j9maj1','j9maj2',\n",
    "            'codej10','j10vote1','j10vote2','j10maj1','j10maj2','codej11','j11vote1','j11vote2','j11maj1','j11maj2',\n",
    "            'codej12','j12vote1','j12vote2','j12maj1','j12maj2','codej13','j13vote1','j13vote2','j13maj1','j13maj2',\n",
    "            'codej14','j14vote1','j14vote2','j14maj1','j14maj2','codej15','j15vote1','j15vote2','j15maj1','j15maj2','j16maj1','j16vote1']\n",
    "    df.drop(labels=del_cols,axis=1,inplace=True)\n",
    "    moredropcolumns=df.columns.tolist() # .tolist?\n",
    "    for i in moredropcolumns:\n",
    "        if len(pd.unique(df[i]))==1:\n",
    "            df.drop(labels=i,axis=1,inplace=True)\n",
    "    df.drop(labels=['casenum','j2vote1','j2vote2','j2maj1','direct1',\n",
    "                          'j2maj2','j3vote1','j3vote2','j3maj1','j3maj2','majvotes','ids'],axis=1,inplace=True)\n",
    "    return df\n",
    "    \n",
    "def dummify(df):\n",
    "    new_cols=df.columns\n",
    "    new_cols=new_cols.tolist()\n",
    "#     keep_cols=['j1score','j2score','j3score','popularpct','electoralpct','closerd','fartherd','dAds3','dF2Ads3',\n",
    "#            'dF1Ads3','dL1Ads3','dL2Ads3','dL3Ads3','dL4Ads3','dL5Ads3','logAds3','logL1Ads3','logL2Ads3','logF1Ads3',\n",
    "#           'logF2Ads3','decade2','propneg','likely_elev2','score','d12','d13','d23','sat_together_count']\n",
    "\n",
    "    float_cols=['j1score','j2score','j3score','popularpct','electoralpct','closerd','fartherd','dAds3','dF2Ads3',\n",
    "           'dF1Ads3','dL1Ads3','dL2Ads3','dL3Ads3','dL4Ads3','dL5Ads3','logAds3','logL1Ads3','logL2Ads3','logF1Ads3',\n",
    "          'logF2Ads3','decade2','propneg','likely_elev2','score','d12','d13','d23',\n",
    "           'judgecitations','experience','experiencetrun','age2trun','agego','assets','ba','liable',\n",
    "            'networth','totalcities','sat_together_count','keytotal','lengthopin','Wopinionlenght','Wtotalcites','age']\n",
    "\n",
    "    remove_for_now=['Ads3','F1Ads3','F2Ads3','L1Ads3','L2Ads3','L3Ads3','L4Ads3','L5Ads3','Unnamed: 0.1','appel1','appel2',\n",
    "               'citevol','codej3','id','usc2sect','usc1sect','age2','distjudg','respond1','respond2','yearb','pred','csb']\n",
    "\n",
    "#    df.drop(labels=remove_for_now,inplace=True,axis=1)\n",
    " \n",
    "    for x in remove_for_now:\n",
    "    \tif x in df.columns:\n",
    "        \tprint \"dropped: \",x\n",
    "        \tdf.drop(labels=[x],inplace=True,axis=1)\n",
    "    \n",
    "    sum1=0\n",
    "    \n",
    "    dummy_cols=[]\n",
    "    for col in df.columns:\n",
    "        if col not in float_cols:\n",
    "            if len(pd.unique(df.ix[:,col]))>100 or (df.ix[:,col].dtype!='float64' and df.ix[:,col].dtype!='int64'): \n",
    "                sum1+= len(pd.unique(df.ix[:,col]))\n",
    "                dummy_cols.append(col)\n",
    "    print \"# of dummy columns: \",sum1\n",
    "    print df.shape\n",
    "    print dummy_cols\n",
    "    df2=pd.get_dummies(df,columns=dummy_cols,dummy_na=True,sparse=True)\n",
    "    print df2.shape\n",
    "    df2.fillna(value=0,inplace=True)\n",
    "    return df2\n",
    "\n",
    "\n",
    "def remove_bad_rows(df_x,df_y):\n",
    "    \n",
    "    #remove rows where codej1==codej2\n",
    "#     df[df.codej1==df.codej2].index\n",
    "    same_cols = df_x[df_x.codej1==df_x.codej2].index\n",
    "    df_x=df_x.drop(same_cols).reset_index(drop=True)\n",
    "    df_y=df_y.drop(same_cols).reset_index(drop=True)\n",
    "    #remove rows where >3 judges occur\n",
    "#     pp = pd.read_csv('../raw/Votelevel_stuffjan2013.csv')\n",
    "#     qq=pp.groupby(by=['casenum']).count()\n",
    "#     pd.unique(qq.month)\n",
    "#     rr=qq[qq.month==6].reset_index()\n",
    "#     rr.shape\n",
    "    \n",
    "    #remove rows where codej2==null\n",
    "    #df[map(lambda x: not(x),pd.notnull(df.ix[:][\"codej2\"]).tolist())]\n",
    "    nan_cols=df_x[map(lambda x: not(x),pd.notnull(df_x.ix[:][\"codej2\"]).tolist())].index\n",
    "    nan_cols.append(df_x[map(lambda x: not(x),pd.notnull(df_x.ix[:][\"codej1\"]).tolist())].index)\n",
    "    df_x=df_x.drop(nan_cols).reset_index(drop=True)\n",
    "    df_y=df_y.drop(nan_cols).reset_index(drop=True)\n",
    "    \n",
    "    return df_x,df_y\n",
    "\n",
    "def drop_dissent(df,drop=['diss','concur','unan']):\n",
    "    \n",
    "    def func(a, b):\n",
    "        return not set(a).isdisjoint(set(b))\n",
    "    \n",
    "    diss_list=[]\n",
    "    for col in df.columns:\n",
    "        for x in drop:\n",
    "            if x in col:\n",
    "                diss_list.append(col)\n",
    "    diss_list=list(set(diss_list))\n",
    "    df.drop(labels=diss_list,axis=1,inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    df,df_y=remove_bad_rows(df,df_y)\n",
    "    df=drop_unneeded_cols(df)\n",
    "    df=drop_dissent(df)\n",
    "    df=dummify(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_x,df_y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_x,df_y=remove_bad_rows(df_x,df_y)\n",
    "df_x=drop_unneeded_cols(df_x)\n",
    "df_x=drop_dissent(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111538, 708)\n",
      "(111538, 1)\n"
     ]
    }
   ],
   "source": [
    "print df_x.shape\n",
    "print df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped:  Ads3\n",
      "dropped:  F1Ads3\n",
      "dropped:  F2Ads3\n",
      "dropped:  L1Ads3\n",
      "dropped:  L2Ads3\n",
      "dropped:  L3Ads3\n",
      "dropped:  L4Ads3\n",
      "dropped:  L5Ads3\n",
      "dropped:  Unnamed: 0.1\n",
      "dropped:  appel1\n",
      "dropped:  appel2\n",
      "dropped:  citevol\n",
      "dropped:  codej3\n",
      "dropped:  id\n",
      "dropped:  usc2sect\n",
      "dropped:  usc1sect\n",
      "dropped:  age2\n",
      "dropped:  distjudg\n",
      "dropped:  respond1\n",
      "dropped:  respond2\n",
      "dropped:  yearb\n",
      "dropped:  pred\n",
      "dropped:  csb\n",
      "# of dummy columns:  4342\n",
      "(111538, 685)\n",
      "['___char', 'amicusapp', 'amicusresp', 'casetyp1', 'casetyp2', 'city', 'codej1', 'codej2', 'congresi', 'endyear', 'ls', 'pos2', 'pos3', 'president', 'president_f1', 'president_f2', 'seatno2', 'seatno3', 'senate', 'senate_f1', 'senate_f2', 'sseatno2', 'totalcites']\n",
      "(111538, 5013)\n"
     ]
    }
   ],
   "source": [
    "df_x=dummify(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=df_x.values\n",
    "y=df_y.ix[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111538, 5013)\n",
      "(111538,)\n",
      "[[  1.  11.  11. ...,   0.   0.   0.]\n",
      " [  1.  11.  11. ...,   0.   0.   0.]\n",
      " [  1.  11.  11. ...,   0.   0.   0.]\n",
      " ..., \n",
      " [  1.   5.   5. ...,   0.   0.   0.]\n",
      " [  1.   5.   5. ...,   0.   0.   0.]\n",
      " [  1.   5.   5. ...,   0.   0.   0.]]\n",
      "[1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print y.shape\n",
    "#sanity check\n",
    "print X[:10]\n",
    "print y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#############################################\n",
    "# Split into training and test set\n",
    "#############################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "print X.nbytes/1024/1024/1024 #size of X in GB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78076, 5013)\n",
      "(78076,)\n",
      "(33462, 5013)\n",
      "(33462,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#df_x,df_y = get_data(1000) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print df_x.info()\n",
    "\n",
    "\n",
    "#check sizes match\n",
    "\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_test.shape\n",
    "print y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#DONT DO FOR RANDOM FOREST\n",
    "\n",
    "# #############################################\n",
    "# # Standard scale\n",
    "# #############################################\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "#############################################\n",
    "# [OPTIONAL]\n",
    "# Random Forest Grid Search\n",
    "#############################################\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "print \"numcores = \",num_cores\n",
    "paramgrid = {'n_estimators': [10, 50, 100, 150, 200], 'max_depth': [1, 5, 10, 15, 20, 25]}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "gridclf = grid_search(X_train, y_train, rf_clf, paramgrid, n_jobs=num_cores)\n",
    "\n",
    "print gridclf.best_params_\n",
    "print gridclf.best_score_\n",
    "#############################################\n",
    "# Random Forest\n",
    "#############################################\n",
    "\n",
    "# Replace labels (in case SVM was run)\n",
    "# y_train[y_train == 0.] = -1.\n",
    "# y_test[y_test == 0.] = -1.\n",
    "\n",
    "\n",
    "\n",
    "#rf_clf = RandomForestClassifier(random_state=42, n_estimators=gridclf.best_params_['n_estimators'], max_depth=[gridclf.best_params_['max_depth'])\n",
    "rf_clf = RandomForestClassifier(random_state=42, **gridclf.best_params_)\n",
    "#                                 class_weight={1.0: 1, -1.0: 150})\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "print_report(y_test, y_pred)\n",
    "\n",
    "#############################################\n",
    "# [OPTIONAL]\n",
    "# Feature importance analysis\n",
    "#############################################\n",
    "\n",
    "top_n = get_top_n_feats(25, rf_clf.feature_importances_, get_columns())\n",
    "\n",
    "for t in top_n:\n",
    "    print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=15,class_weight={1.0: 1, -1.0: 35})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.18      0.66      0.28      1370\n",
      "          1       0.98      0.87      0.92     32092\n",
      "\n",
      "avg / total       0.95      0.86      0.90     33462\n",
      "\n",
      "CPU times: user 59.2 s, sys: 420 ms, total: 59.7 s\n",
      "Wall time: 59.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "print_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.07      0.91      0.13      1370\n",
      "          1       0.99      0.48      0.65     32092\n",
      "\n",
      "avg / total       0.95      0.50      0.63     33462\n",
      "\n",
      "CPU times: user 59.7 s, sys: 400 ms, total: 1min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##class weight: 1 and 70\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "print_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wopinionlenght', '0.0238311762751']\n",
      "['Wlengthopin', '0.0229291335576']\n",
      "['lengthopin', '0.0220870675947']\n",
      "['votingvalence', '0.0181971102661']\n",
      "['Wtotalcites', '0.0134327669155']\n",
      "['opinstat', '0.0108831510041']\n",
      "['propneg', '0.010627325893']\n",
      "['decade2', '0.00923690684669']\n",
      "['d13', '0.00923270714389']\n",
      "['signed', '0.0076670435348']\n",
      "['negativecites', '0.00755880357634']\n",
      "['j3score', '0.00753907933609']\n",
      "['fartherd', '0.00729415435453']\n",
      "['treat', '0.00718588724809']\n",
      "['distance', '0.007172403572']\n",
      "['decade', '0.00698642288304']\n",
      "['pagelgth', '0.00696001031277']\n",
      "['day', '0.00684200675229']\n",
      "['state', '0.00679113479606']\n",
      "['sat_together_count', '0.0067014658775']\n",
      "['j1score', '0.00653692884376']\n",
      "['liberalvote', '0.00641137353297']\n",
      "['j2score', '0.00620303280375']\n",
      "['d12', '0.00602330797119']\n",
      "['d23', '0.00599882287965']\n"
     ]
    }
   ],
   "source": [
    "##class weight: 1 and 35\n",
    "top_n = get_top_n_feats(25, rf_clf.feature_importances_, df_x.columns)\n",
    "\n",
    "for t in top_n:\n",
    "    print t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exogenous:\n",
    "\n",
    "Citation:\n",
    "['Wtotalcites', '0.0134327669155']\n",
    "['negativecites', '0.00755880357634']\n",
    "\n",
    "Endogenous:\n",
    "['Wopinionlenght', '0.0238311762751']\n",
    "['Wlengthopin', '0.0229291335576']\n",
    "['lengthopin', '0.0220870675947']\n",
    "['votingvalence', '0.0181971102661']\n",
    "['opinstat', '0.0108831510041']\n",
    "\n",
    "Seating:\n",
    "['sat_together_count', '0.0067014658775']\n",
    "\n",
    "\n",
    "Unclassif:\n",
    "['propneg', '0.010627325893']\n",
    "['decade2', '0.00923690684669']\n",
    "['d13', '0.00923270714389']\n",
    "['signed', '0.0076670435348']\n",
    "['fartherd', '0.00729415435453']\n",
    "\n",
    "dxy - dist. b/w judges - spatial metric, estimate of ideology (lib/cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['votingvalence', '0.0261547496099']\n",
      "['lengthopin', '0.0230530517623']\n",
      "['Wopinionlenght', '0.0225879213156']\n",
      "['Wlengthopin', '0.0224313759724']\n",
      "['opinstat', '0.0141275262243']\n",
      "['Wtotalcites', '0.011530246961']\n",
      "['decade2', '0.0096729089471']\n",
      "['propneg', '0.00823910550041']\n",
      "['negativecites', '0.00796099978763']\n",
      "['signed', '0.00756256306951']\n",
      "['decade', '0.00755522639548']\n",
      "['j3score', '0.00742370899574']\n",
      "['d13', '0.00731213796115']\n",
      "['distance', '0.0069955304234']\n",
      "['sat_together_count', '0.006940075614']\n",
      "['day', '0.00675750405747']\n",
      "['state', '0.00663529136889']\n",
      "['liberalvote', '0.00645739940594']\n",
      "['treat', '0.00643418098166']\n",
      "['d23', '0.00591955394343']\n",
      "['weeks', '0.00582960418287']\n",
      "['j2score', '0.00582324043509']\n",
      "['month', '0.00573972915478']\n",
      "['fartherd', '0.00567211057412']\n",
      "['caseload', '0.00566699254826']\n"
     ]
    }
   ],
   "source": [
    "##class weight: 1 and 70\n",
    "top_n = get_top_n_feats(25, rf_clf.feature_importances_, df_x.columns)\n",
    "\n",
    "for t in top_n:\n",
    "    print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['votingvalence', '0.031820253526']\n",
      "['Wopinionlenght', '0.0307333470406']\n",
      "['lengthopin', '0.0259333289836']\n",
      "['Wlengthopin', '0.0194242829752']\n",
      "['opinstat', '0.0114878351882']\n",
      "['Wtotalcites', '0.0111129239341']\n",
      "['decade2', '0.0103847135557']\n",
      "['decade', '0.00872973047309']\n",
      "['signed', '0.0082874547415']\n",
      "['distance', '0.00711918735182']\n",
      "['day', '0.0068660132445']\n",
      "['negativecites', '0.00674048858062']\n",
      "['propneg', '0.00657687569546']\n",
      "['state', '0.00615852611257']\n",
      "['sat_together_count', '0.00610524337817']\n",
      "['j3score', '0.00599288617793']\n",
      "['d13', '0.00595437915445']\n",
      "['popularpct', '0.00579284283268']\n",
      "['totalcites_0.0', '0.00561865680217']\n",
      "['procedur', '0.00555179653346']\n",
      "['caseload', '0.00552298275005']\n",
      "['weeks', '0.00540221329263']\n",
      "['d23', '0.00520571465573']\n",
      "['d12', '0.00520386912836']\n",
      "['month', '0.00513730043263']\n"
     ]
    }
   ],
   "source": [
    "##class weight: 1 and 150\n",
    "top_n = get_top_n_feats(25, rf_clf.feature_importances_, df_x.columns)\n",
    "\n",
    "for t in top_n:\n",
    "    print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
