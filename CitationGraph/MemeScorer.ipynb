{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import copy, os, csv, time\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_filename = None\n",
    "g_case_list = None\n",
    "g_year_map = None\n",
    "\n",
    "def get_file_obj(filename):\n",
    "    return open(filename, 'r')\n",
    "\n",
    "def get_year_map(filename):\n",
    "    \n",
    "    global g_filename\n",
    "    global g_case_list\n",
    "    global g_year_map\n",
    "    \n",
    "    if (g_filename is not None) and (g_filename == filename):\n",
    "        if (g_case_list is not None) and (g_year_map is not None):\n",
    "            return g_year_map, g_case_list\n",
    "        \n",
    "    \n",
    "    f = get_file_obj(filename)\n",
    "    \n",
    "    year_map = {}\n",
    "    case_list = []\n",
    "    \n",
    "    for line in f:\n",
    "        year, from_case, to_case = line[:-1].split(',')\n",
    "        \n",
    "        if from_case not in year:\n",
    "            year_map[from_case] = int(year)\n",
    "            case_list.append(from_case)\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "    g_filename = filename\n",
    "    g_year_map = year_map\n",
    "    g_case_list = case_list\n",
    "    \n",
    "    \n",
    "    \n",
    "    return year_map, case_list\n",
    "\n",
    "\n",
    "def get_graph(filename, b_enforce_random = False):\n",
    "    \n",
    "    if b_enforce_random:\n",
    "        random_start = 0\n",
    "        random_end = 5000\n",
    "        random_target = random_start + (random_end - random_start) / 2\n",
    "    \n",
    "    year_map, case_list = get_year_map(filename)\n",
    "    \n",
    "    # Begin building citation graph\n",
    "    f = get_file_obj(filename)    \n",
    "    g = nx.DiGraph()\n",
    "    \n",
    "    for line in f:\n",
    "    \n",
    "        year, from_case, to_case = line[:-1].split(',')\n",
    "\n",
    "        # Citing a future case is invalid\n",
    "        if (to_case in year_map) and (from_case in year_map) and (year_map[from_case] < year_map[to_case]):\n",
    "            continue\n",
    "            \n",
    "        # If they cite each other, it is most likely that both are a wrong edge\n",
    "        if (to_case in g) and (from_case in g[to_case]):\n",
    "            del g[to_case][from_case]\n",
    "            continue\n",
    "        \n",
    "        # Add edges\n",
    "        if (b_enforce_random == False) or (random_target == random.randrange(random_start, random_end)):\n",
    "            g.add_edge(from_case, to_case)\n",
    "#             g.node[from_case]['year']=int(year)\n",
    "            g.node[from_case]['ifCounted']=False\n",
    "            g.node[from_case]['isMemer']=False\n",
    "            g.node[from_case]['citesMemer']=False\n",
    "            g.node[to_case]['ifCounted']=False\n",
    "            g.node[to_case]['isMemer']=False\n",
    "            g.node[to_case]['citesMemer']=False\n",
    "                \n",
    "    f.close()\n",
    "    \n",
    "    return g\n",
    "    \n",
    "\n",
    "def display_graph(graph):\n",
    "    \n",
    "    print graph.nodes()\n",
    "\n",
    "\n",
    "def topological_sort(graph):\n",
    "    \"\"\"\n",
    "    Sorts graph by year.\n",
    "    Argument: graph\n",
    "    Returns: a list of nodes of the graph sorted by dependencies\n",
    "    \"\"\"\n",
    "    \n",
    "    global g_filename\n",
    "    \n",
    "    if g_filename is None:\n",
    "        return graph.nodes()\n",
    "    \n",
    "    year_map, case_list = get_year_map(g_filename)\n",
    "    \n",
    "    return case_list\n",
    "\n",
    "def freshen_graph(g):\n",
    "    for node in g.nodes():\n",
    "        g.node[node]['ifCounted']=False\n",
    "        g.node[node]['isMemer']=False\n",
    "        g.node[node]['citesMemer']=False\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gramScorer(gram,sorted_list,graph,gram_dict,verbose=0):\n",
    "    \"\"\"\n",
    "    Calculates meme score for each ngram.\n",
    "    Arguments:\n",
    "    gram: an n-gram or phrase for which meme score to be calculated\n",
    "    sorted_list: a sorted list of all nodes in graph\n",
    "    graph: a NetworkX DAG of nodes/cases with edges\n",
    "    gram_dict: dict storing n-grams\n",
    "    Returns:\n",
    "    meme_score: final meme_score of the n-gram\n",
    "\"\"\"\n",
    "    graph_size = len(sorted_list) #number of nodes\n",
    "    if verbose>=1:\n",
    "        print \"graph_size is\",graph_size\n",
    "    dm2m=0\n",
    "    d2m=0\n",
    "    dm2n=0\n",
    "    d2n=0\n",
    "    memers=0\n",
    "    nonmemers=0\n",
    "    \n",
    "    #every node stores 3 vars - isMemer, citesMemer, ifCounted (in sum)\n",
    "    \n",
    "    for node in sorted_list: #list of nodes sorted topologically\n",
    "        \n",
    "        if node not in graph:\n",
    "            continue\n",
    "        \n",
    "        if not graph.node[node]['ifCounted']: #if not counted in sum\n",
    "            \n",
    "            if verbose>=3:\n",
    "                print node,graph.node[node]\n",
    "                \n",
    "            if node in gram_dict.keys():\n",
    "\n",
    "                if gram_dict[node].has_key(gram): #if gram present\n",
    "                    memers+=1 #has meme\n",
    "                    graph.node[node]['isMemer']=True\n",
    "\n",
    "                else:\n",
    "                    nonmemers+=1\n",
    "\n",
    "            graph.node[node]['ifCounted']=True\n",
    "\n",
    "\n",
    "            if len(graph.successors(node))>0: #has children (citers)\n",
    "                for child in graph.successors_iter(node):\n",
    "\n",
    "                    if graph.node[child]['isMemer']==True: #soft-check if child has gram\n",
    "                        graph.node[node]['citesMemer']=True\n",
    "                    elif gram_dict.has_key(child) and gram_dict[child].has_key(gram): #hard-check using dictionary\n",
    "                        graph.node[child]['isMemer']=True\n",
    "                        graph.node[node]['citesMemer']=True\n",
    "                        break\n",
    "#                     else:\n",
    "#                         nonmemers+=1\n",
    "\n",
    "            if verbose>=3:\n",
    "                print node,graph.node[node]\n",
    "            if graph.node[node]['isMemer']==True and graph.node[node]['citesMemer']==True:\n",
    "                dm2m+=1 #memer cites memer\n",
    "\n",
    "            elif graph.node[node]['isMemer']==True and graph.node[node]['citesMemer']==False:\n",
    "                if len(graph.successors(node))!=0: #make sure childless nodes not counted\n",
    "                    dm2n+=1 #memer cites non-memers\n",
    "\n",
    "            if graph.node[node]['citesMemer']==True:\n",
    "                d2m+=1 #cites memers\n",
    "\n",
    "            elif graph.node[node]['citesMemer']==False:\n",
    "                if len(graph.successors(node))!=0: #make sure childless nodes not counted\n",
    "                    d2n+=1 #cites non-memers\n",
    "        elif verbose>=2:\n",
    "                print str(node)+\" is counted.\"\n",
    "    \n",
    "#     assert memers+nonmemers==graph_size #sanity check for memer size\n",
    "    if verbose>=1:\n",
    "        print \"memers =\",memers\n",
    "        print \"nonmemers =\",nonmemers\n",
    "        print \"dm2m =\",dm2m\n",
    "        print \"d2m =\",d2m\n",
    "        print \"dm2n =\",dm2n\n",
    "        print \"d2n =\",d2n\n",
    "\n",
    "    prop_score = (float(dm2m)/(d2m+3.))/((dm2n+3.)/(d2n+3.)) #ratio of sticking factor by sparking factor\n",
    "    #we take a shifted prop. score to make sure score not infinite\n",
    "    freq = float(memers)/(graph_size) #ratio of # of memers for that n-gram to size of graph\n",
    "    meme_score = prop_score*freq #prop_score x meme frequency\n",
    "    \n",
    "    if verbose>=1:\n",
    "        print \"prop_score =\",prop_score\n",
    "        print \"freq =\",freq\n",
    "        print \"meme_score =\",meme_score\n",
    "\n",
    "    return meme_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_file = 'data/graph_stripped.csv'\n",
    "data_file = 'data/graph_mini.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of nodes:  130502\n",
      "total # of edges:  444130\n",
      "CPU times: user 4.94 s, sys: 148 ms, total: 5.09 s\n",
      "Wall time: 5.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g = get_graph(data_file)\n",
    "print \"total # of nodes: \",len(g.nodes())\n",
    "print \"total # of edges: \",len(g.edges())\n",
    "\n",
    "# g = eliminate_cycles(g)\n",
    "# print \"total # of non-cyclic nodes: \",len(g.nodes())\n",
    "# print \"total # of non-cyclic edges: \",len(g.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_list = topological_sort(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of cases is:  594822\n"
     ]
    }
   ],
   "source": [
    "print \"num of cases is: \", len(sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir='data/n_grams/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_files(directory, pattern):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for basename in files:\n",
    "            \n",
    "            if basename == '.DS_Store':\n",
    "                continue\n",
    "            \n",
    "            if fnmatch.fnmatch(basename, pattern):\n",
    "                filename = os.path.join(root, basename)\n",
    "                yield filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "gram_dict={}\n",
    "#test=['XFKEIQ.txt','XFKK8M.txt','XFLD3P.txt']\n",
    "\n",
    "#Generate dictionary of n-grams\n",
    "\n",
    "\n",
    "\n",
    "# for filename in os.listdir(data_dir):\n",
    "for filename in find_files(data_dir, '*'):\n",
    "    f = open(filename, 'r')\n",
    "    name = filename[:-4]\n",
    "    gram_dict[name]={}\n",
    "    \n",
    "    for line in f:\n",
    "        text, count = line.rsplit(',',1)\n",
    "        count=int(count[:-2])\n",
    "        \n",
    "        if count>1:\n",
    "            gram_dict[name][text]=count\n",
    "            \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_size is 594822\n",
      "memers = 0\n",
      "nonmemers = 0\n",
      "dm2m = 0\n",
      "d2m = 0\n",
      "dm2n = 0\n",
      "d2n = 102869\n",
      "prop_score = 0.0\n",
      "freq = 0.0\n",
      "meme_score = 0.0\n",
      "graph_size is 594822\n",
      "memers = 0\n",
      "nonmemers = 0\n",
      "dm2m = 0\n",
      "d2m = 0\n",
      "dm2n = 0\n",
      "d2n = 102869\n",
      "prop_score = 0.0\n",
      "freq = 0.0\n",
      "meme_score = 0.0\n",
      "graph_size is 594822\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-5bbad9fdf9c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'testset=gram_dict.keys()\\nscore_dict={}\\n\\nfor i in testset[:1]: #testset of nodes\\n    for gram in gram_dict[i]:\\n        if not score_dict.has_key(gram) and gram_dict[i][gram]>=2: #not already scored, freq >= 2\\n            g = freshen_graph(g) #set all values to False\\n            gramScore = gramScorer(gram,sorted_list,g,gram_dict,1)\\n            score_dict[gram] = (i,gramScore) #stores first node encountered and meme score\\n            \\n            if int(gramScore)!=0: #only print those with non-zero scores\\n                print i,gram,gramScore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-8027ae6b2ad7>\u001b[0m in \u001b[0;36mgramScorer\u001b[0;34m(gram, sorted_list, graph, gram_dict, verbose)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mnonmemers\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ifCounted'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testset=gram_dict.keys()\n",
    "score_dict={}\n",
    "\n",
    "for i in testset[:1]: #testset of nodes\n",
    "    for gram in gram_dict[i]:\n",
    "        if not score_dict.has_key(gram) and gram_dict[i][gram]>=2: #not already scored, freq >= 2\n",
    "            g = freshen_graph(g) #set all values to False\n",
    "            gramScore = gramScorer(gram,sorted_list,g,gram_dict,1)\n",
    "            score_dict[gram] = (i,gramScore) #stores first node encountered and meme score\n",
    "            \n",
    "            if int(gramScore)!=0: #only print those with non-zero scores\n",
    "                print i,gram,gramScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I have': ('XFVA4E', 0.0),\n",
       " 'It is': ('XFLCRA', 0.0),\n",
       " 'It is insisted': ('XFLCRA', 0.0),\n",
       " 'N. Y': ('XFLCRA', 0.0),\n",
       " 'Power and Kindred': ('XFLCRA', 0.0),\n",
       " 'We are': ('XFLCRA', 0.0),\n",
       " 'We think': ('XFLCRA', 0.0),\n",
       " 'acquiesced in': ('XFLCRA', 0.0),\n",
       " 'advised of': ('XFLCRA', 0.0),\n",
       " 'appoint an assignee': ('XFVA4E', 0.0),\n",
       " 'are not': ('XFLCRA', 0.0),\n",
       " 'are of': ('XFLCRA', 0.0),\n",
       " 'are of opinion': ('XFLCRA', 0.0),\n",
       " 'as such agents': ('XFLCRA', 0.0),\n",
       " 'at least two-thirds': ('XFKMOB', 0.0),\n",
       " 'at such meeting': ('XFKMOB', 0.0),\n",
       " 'averred that': ('XFLCRA', 0.0),\n",
       " 'be allowed': ('XFLCRA', 0.0),\n",
       " 'be pleaded': ('XFLCRA', 0.0),\n",
       " 'be regarded': ('XFKMOB', 0.0),\n",
       " 'be regarded as': ('XFKMOB', 0.0),\n",
       " 'be set': ('XFLCRA', 0.0),\n",
       " 'been called': ('XFKMOB', 0.0),\n",
       " 'been called by': ('XFKMOB', 0.0),\n",
       " 'bill does': ('XFKMOB', 0.0),\n",
       " 'bill does not': ('XFKMOB', 0.0),\n",
       " 'bills are': ('XFLCRA', 0.0),\n",
       " 'bills contain': ('XFLCRA', 0.0),\n",
       " 'board of directors': ('XFKMOB', 0.0),\n",
       " 'called by': ('XFKMOB', 0.0),\n",
       " 'coal was': ('XFKEI5', 0.0),\n",
       " 'complainant had': ('XFLCRA', 0.0),\n",
       " 'complainant has': ('XFLCRA', 0.0),\n",
       " 'complainant has not': ('XFLCRA', 0.0),\n",
       " 'complained of': ('XFLCRA', 0.0),\n",
       " 'course of his': ('XFLCRA', 0.0),\n",
       " 'course of his agency': ('XFLCRA', 0.0),\n",
       " 'different lines': ('XFKMOB', 0.0),\n",
       " 'different lines of railroad': ('XFKMOB', 0.0),\n",
       " 'directory only': ('XFKMOB', 0.0),\n",
       " 'do not': ('XFLCRA', 0.0),\n",
       " 'does not': ('XFKMOB', 0.0),\n",
       " 'enough if': ('XFLCRA', 0.0),\n",
       " 'entered into': ('XFLCRA', 0.0),\n",
       " 'established by': ('XFLCRA', 0.0),\n",
       " 'executed by': ('XFKMOB', 0.0),\n",
       " 'facts constituting': ('XFLCRA', 0.0),\n",
       " 'fraudulent contract': ('XFLCRA', 0.0),\n",
       " 'fraudulent contracts': ('XFLCRA', 0.0),\n",
       " 'fraudulent transactions': ('XFLCRA', 0.0),\n",
       " 'has been': ('XFLCRA', 0.042388952669153074),\n",
       " 'has not': ('XFLCRA', 0.0),\n",
       " 'have been': ('XFLCRA', 0.0),\n",
       " 'have been called': ('XFKMOB', 0.0),\n",
       " 'he is': ('XFLCRA', 0.0),\n",
       " 'his agency': ('XFLCRA', 0.0),\n",
       " 'his bill': ('XFLCRA', 0.0),\n",
       " 'important questions': ('XFVA4E', 0.0),\n",
       " 'important questions of law': ('XFVA4E', 0.0),\n",
       " 'in open meeting': ('XFKMOB', 0.0),\n",
       " 'insisted that': ('XFLCRA', 0.0),\n",
       " 'is averred': ('XFLCRA', 0.0),\n",
       " 'is averred that': ('XFLCRA', 0.0),\n",
       " 'is enough': ('XFLCRA', 0.0),\n",
       " 'is enough if': ('XFLCRA', 0.0),\n",
       " 'is insisted': ('XFLCRA', 0.0),\n",
       " 'is insisted that': ('XFLCRA', 0.0),\n",
       " 'is not': ('XFLCRA', 0.03415516601636476),\n",
       " 'is that': ('XFKMOB', 0.0),\n",
       " 'is well': ('XFKMOB', 0.0),\n",
       " 'it aside': ('XFLCRA', 0.0),\n",
       " 'it be': ('XFLCRA', 0.0),\n",
       " 'it is': ('XFLCRA', 0.030714635087527507),\n",
       " 'it was': ('XFLCRA', 0.04176959601455556),\n",
       " 'its agents': ('XFLCRA', 0.0),\n",
       " 'its lands': ('XFLCRA', 0.0),\n",
       " 'last past': ('XFLCRA', 0.0),\n",
       " 'law and fact': ('XFVA4E', 0.0),\n",
       " 'least two-thirds': ('XFKMOB', 0.0),\n",
       " 'lines of railroad': ('XFKMOB', 0.0),\n",
       " 'made in': ('XFLCRA', 0.0),\n",
       " 'matters of form': ('XFKMOB', 0.0),\n",
       " 'meeting assembled': ('XFKMOB', 0.0),\n",
       " 'necessary parties': ('XFLCRA', 0.0),\n",
       " 'need not': ('XFLCRA', 0.0),\n",
       " 'not be': ('XFLCRA', 0.04842799106860044),\n",
       " 'not discovered': ('XFLCRA', 0.0),\n",
       " 'not of': ('XFKMOB', 0.0),\n",
       " 'of such meeting': ('XFKMOB', 0.0),\n",
       " 'open meeting': ('XFKMOB', 0.0),\n",
       " 'our judgment': ('XFKMOB', 0.0),\n",
       " 'paid for': ('XFLCRA', 0.0),\n",
       " 'paid for it': ('XFLCRA', 0.0),\n",
       " 'preferred stock': ('XFLCRA', 0.0),\n",
       " 'principles of equity': ('XFLCRA', 0.0),\n",
       " 'questions of law': ('XFVA4E', 0.0),\n",
       " 'railroad company': ('XFKMOB', 0.0),\n",
       " 'received from': ('XFLCRA', 0.0),\n",
       " 'received on': ('XFLCRA', 0.0),\n",
       " 'regarded as': ('XFKMOB', 0.0),\n",
       " 'regarded as directory': ('XFKMOB', 0.0),\n",
       " 'represented at': ('XFKMOB', 0.0),\n",
       " 'required by': ('XFKMOB', 0.0),\n",
       " 'respondents Power': ('XFLCRA', 0.0),\n",
       " 'respondents Power and Kindred': ('XFLCRA', 0.0),\n",
       " 'said lands': ('XFLCRA', 0.0),\n",
       " 'set it': ('XFLCRA', 0.0),\n",
       " 'several bills': ('XFLCRA', 0.0),\n",
       " 'show that': ('XFLCRA', 0.0),\n",
       " 'stated in': ('XFLCRA', 0.0),\n",
       " 'stock represented': ('XFKMOB', 0.0),\n",
       " 'stockholders in meeting': ('XFKMOB', 0.0),\n",
       " 'such agents': ('XFLCRA', 0.0),\n",
       " 'such meeting': ('XFKMOB', 0.0),\n",
       " 'such profits': ('XFLCRA', 0.0),\n",
       " 'their face': ('XFLCRA', 0.0),\n",
       " 'they are': ('XFLCRA', 0.0),\n",
       " 'they have': ('XFLCRA', 0.0),\n",
       " 'they have been': ('XFLCRA', 0.0),\n",
       " 'unadministered assets': ('XFVA4E', 0.0),\n",
       " 'unconditional delivery': ('XFKEI5', 0.0),\n",
       " 'vote at such meeting': ('XFKMOB', 0.0),\n",
       " 'was not': ('XFLCRA', 0.05064311050665684),\n",
       " 'whatever he': ('XFLCRA', 0.0)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel version 1: grams parallelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_list=[]\n",
    "dic = {'A':('a',1),'B':('b',2),'C':('c',3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_list.append(['B',('b',1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A', ('a', 1)], ['B', ('b', 1)]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def parallel_scorer(gram):\n",
    "    score_list=[]\n",
    "    h=g.copy() #make copy of graph since we overwrite g\n",
    "    h = freshen_graph(h) #set all values to False\n",
    "    topo_h=topological_sort(h)\n",
    "    gramScore = gramScorer(gram,topo_h,h,gram_dict,0)\n",
    "    #score_dict[gram] = (i,gramScore) #stores first node encountered and meme score\n",
    "    score_list.append([gram,(i,gramScore)])\n",
    "    if gramScore!=0: #only print those with non-zero scores\n",
    "        print i,gram,gramScore\n",
    "    return score_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gram_checker={}\n",
    "all_scores={}\n",
    "batch_scores=[]\n",
    "\n",
    "if not gram_checker.has_key(gram) and gram_dict[i][gram]>=2: #not already scored, freq >= 2\n",
    "    gram_checker[gram]=1 #done\n",
    "    \n",
    "    for i in testset[:10]:\n",
    "        jobs=Parallel(n_jobs=num_cores)(delayed(parallel_scorer)(gram) for gram in gram_dict[i])\n",
    "        batch_scores.append(jobs)\n",
    "\n",
    "for x in batch_scores:\n",
    "    for y in x:\n",
    "        all_scores[y[0]]=y[1] #all_scores['ngram'] = ('case_id',score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"gram_scores.csv\", \"wb\") as f:\n",
    "    csv.writer(f).writerows((k,) + v for k, v in score_dict.iteritems())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "print \"num_cores is: \",num_cores\n",
    "print \"parallel jobs started\"\n",
    "jobs=Parallel(n_jobs=num_cores)(delayed(do_to_case)(case) for case in caseList)\n",
    "bigout=[]\n",
    "bignew=pd.DataFrame()\n",
    "print \"parallel jobs done\"\n",
    "print \"concatenating df's and out's\"\n",
    "for x in jobs:\n",
    "    if bignew.empty:\n",
    "        bignew=x[0]\n",
    "    else:\n",
    "        bignew=pd.concat([bignew,x[0]],ignore_index=True)\n",
    "    bigout = bigout + x[1]\n",
    "    gc.collect()\n",
    "\n",
    "batch = 25\n",
    "for i in range(batch):\n",
    "    with open(\"gram_scores_\"+str(batch) \".csv\", \"wb\") as f:\n",
    "        csv.writer(f).writerows((k,) + v for k, v in score_dict.iteritems())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Parallel version 2: years/cases parallelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880_complete  1884_complete  1888_complete  1892_complete  1896_complete\r\n",
      "1881_complete  1885_complete  1889_complete  1893_complete  1897_complete\r\n",
      "1882_complete  1886_complete  1890_complete  1894_complete  1898_complete\r\n",
      "1883_complete  1887_complete  1891_complete  1895_complete  1899_complete\r\n"
     ]
    }
   ],
   "source": [
    "!ls '/scratch/sv1239/projects/mlcs/raw/citation_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir='/scratch/sv1239/projects/mlcs/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parent_scorer(dirname):\n",
    "    \n",
    "    gram_dict={}\n",
    "    #test=['XFKEIQ.txt','XFKK8M.txt','XFLD3P.txt']\n",
    "\n",
    "    #Generate dictionary of n-grams\n",
    "\n",
    "    for filename in os.listdir(data_dir):\n",
    "        f = open(data_dir+filename, 'r')\n",
    "        name = filename[:-4]\n",
    "        gram_dict[name]={}\n",
    "\n",
    "        for line in f:\n",
    "            text, count = line.rsplit(',',1)\n",
    "            count=int(count[:-2])\n",
    "\n",
    "            if count>1:\n",
    "                gram_dict[name][text]=count\n",
    "\n",
    "        f.close()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: creating gram-dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gram_dict(start_year,end_year):\n",
    "    \"\"\"\n",
    "    saves a .csv file containing case_id x gram x freq. data of all id's from start to end year.\n",
    "    \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2a: inner parallel loop over gram-dicts (modified meme-scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2b: outer loop over cases in a year, and grams in a case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 3: outer outer parallel loop over years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parallel_scorer_by_year(gram):\n",
    "    #same as parallel_scorer\n",
    "    return score_list\n",
    "\n",
    "def file_list(directory):\n",
    "    \"\"\"\n",
    "    Returns list containing names of files in directory. Will parallelize over these.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 1: generate gramdicts for each decade (for size).\n",
    "# step 2: modify meme_scorer func so it stores dm2m, d2m etc. This is calculated parallely over all gramdicts.\n",
    "# step 3: sum up all dm2m etc. to get final meme_score for each gram.\n",
    "# step 3.5: loop over grams in a case for a year\n",
    "# step 4: loop over cases in a year\n",
    "# step 5: outer outer parallel loop over cases in parallelized years\n",
    "\n",
    "# 5-4-3.5-3-2-1.\n",
    "\n",
    "# 2 parallelizations - 1) over years (folders) 2) over gram_dict for score calculation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
